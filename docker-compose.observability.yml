# Docker Compose for Observability Stack
# 
# This provides a complete observability environment for the AMIRA ASR server
# including Prometheus, Grafana, and Jaeger for production monitoring.

services:
  # Prometheus for metrics collection
  prometheus:
    image: prom/prometheus:latest
    container_name: amira-prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./config/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--web.enable-lifecycle'
      - '--web.enable-admin-api'
    networks:
      - observability

  # Grafana for visualization
  grafana:
    image: grafana/grafana:latest
    container_name: amira-grafana
    ports:
      - "3001:3000"
    volumes:
      - grafana_data:/var/lib/grafana
      - ./config/grafana/dashboards:/etc/grafana/provisioning/dashboards
      - ./config/grafana/datasources:/etc/grafana/provisioning/datasources
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_USERS_ALLOW_SIGN_UP=false
    networks:
      - observability
    depends_on:
      - prometheus

  # Jaeger for distributed tracing
  jaeger:
    image: jaegertracing/all-in-one:latest
    container_name: amira-jaeger
    ports:
      - "16686:16686"  # Jaeger UI
      - "14268:14268"  # HTTP collector
      - "14250:14250"  # gRPC collector
    environment:
      - COLLECTOR_OTLP_ENABLED=true
    networks:
      - observability

  # AMIRA ASR Server (production-ready)
  amira-asr:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: amira-asr-server
    ports:
      - "8057:8057"
    environment:
      - RUST_LOG=info
      - TRITON_ENDPOINT=http://triton:8001
      - JAEGER_ENDPOINT=http://jaeger:14268/api/traces
    networks:
      - observability
      - triton
    depends_on:
      - prometheus
      - jaeger
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8057/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Triton Inference Server (if needed)
  triton:
    image: nvcr.io/nvidia/tritonserver:23.10-py3
    container_name: amira-triton
    ports:
      - "8000:8000"
      - "8001:8001" 
      - "8002:8002"
    volumes:
      - ./model-repo:/models
    command: tritonserver --model-repository=/models --allow-http=true --allow-grpc=true
    networks:
      - triton
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

networks:
  observability:
    driver: bridge
  triton:
    driver: bridge

volumes:
  prometheus_data:
  grafana_data: